{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "##   Packages Used\n",
    "##\n",
    "\n",
    "import pandas as pd\n",
    "import gdown\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import LinAlgError\n",
    "from IPython.display import HTML\n",
    "\n",
    "##\n",
    "##   Data Upload\n",
    "##\n",
    "\n",
    "file_id = '1JjYmvA8qTPOh_dVAVkvsapP-xtes7F4h'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "output = 'spotify_songs.csv'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "songs = pd.read_csv('spotify_songs.csv')\n",
    "\n",
    "##\n",
    "##   Data Preprocessing\n",
    "##\n",
    "\n",
    "def standardize_date(dates):\n",
    "    \"\"\"\n",
    "    Standardizes a list of date strings to the format 'YYYY-MM-DD'.\n",
    "\n",
    "    Parameters:\n",
    "        dates (iterable): An iterable containing date strings in various formats\n",
    "                          ('YYYY', 'YYYY-MM', 'YYYY-MM-DD').\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Pandas Series with dates converted to datetime format, where:\n",
    "                   - 'YYYY' is converted to 'YYYY-01-01'\n",
    "                   - 'YYYY-MM' is converted to 'YYYY-MM-01'\n",
    "                   - 'YYYY-MM-DD' remains unchanged\n",
    "                   Invalid dates will be set as NaT (Not a Time).\n",
    "    \"\"\"\n",
    "    standardized_dates = []\n",
    "    for date in dates:\n",
    "        if pd.isna(date):\n",
    "            standardized_dates.append(date)\n",
    "        elif len(date) == 4:\n",
    "            standardized_dates.append(f\"{date}-01-01\")\n",
    "        elif len(date) == 7:\n",
    "            standardized_dates.append(f\"{date}-01\")\n",
    "        else:\n",
    "            standardized_dates.append(date)\n",
    "\n",
    "    return pd.to_datetime(standardized_dates, errors='coerce')\n",
    "\n",
    "\n",
    "def preprocesse_songs(df):\n",
    "    df.drop(columns=['playlist_name', 'playlist_id'], inplace=True)\n",
    "    df.drop_duplicates(subset=['track_name','track_artist'], inplace=True)\n",
    "    df = df[(df.duration_ms > df.duration_ms.quantile(0.01))]\n",
    "    df.dropna(inplace=True)\n",
    "    df['track_album_release_date'] = standardize_date(df['track_album_release_date'])\n",
    "    df['release_year']  = df['track_album_release_date'].dt.year\n",
    "    df = df.drop(columns=['track_album_release_date'])\n",
    "    encoder = LabelEncoder()\n",
    "    df['track_artist_label'] = encoder.fit_transform(df['track_artist'])\n",
    "    df['track_album_id_label'] = encoder.fit_transform(df['track_album_id'])\n",
    "    df['artist_track'] = df.apply(lambda x: f\"{x['track_artist']} - {x['track_name']}\", axis=1)\n",
    " \n",
    "    return df\n",
    "\n",
    "songs = preprocesse_songs(songs)\n",
    "\n",
    "\n",
    "##\n",
    "##   Clustering Process\n",
    "##\n",
    "\n",
    "clustering_data =  songs[['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "       'valence', 'tempo','track_artist_label','release_year']]\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "songs.loc[:, 'kmeans_labels'] = kmeans.fit_predict(clustering_data)\n",
    "clustering_data.loc[:, 'kmeans_labels'] = kmeans.fit_predict(clustering_data)\n",
    "\n",
    "##\n",
    "##   Prediction Process\n",
    "##\n",
    "\n",
    "## User Input - These should pprobably be drop down menus using the artist_track column as options and a few options of how many songs\n",
    "## the user would like to be recommended as the output (e.g.: 10, 20, or 30)\n",
    "song_name = input('Input the songs artist and song name as \"Artist - Track\":\\n')\n",
    "# Should we have a max here? 100 maybe?\n",
    "top_n = int(input('How many songs would you like to be recommended?\\n'))\n",
    "\n",
    "\n",
    "user_input = songs[(songs.artist_track==song_name)]\n",
    "\n",
    "num_user_input = clustering_data.loc[user_input.index]\n",
    "\n",
    "\n",
    "like_songs = clustering_data[(clustering_data.kmeans_labels.values==num_user_input.kmeans_labels.values)]\n",
    "like_songs = like_songs.drop(index=user_input.index)\n",
    "\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "cov_matrix = np.cov(like_songs, rowvar=False)\n",
    "\n",
    "try:\n",
    "    # Inverse of the covariance matrix\n",
    "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "except LinAlgError:\n",
    "    # If the covariance matrix is singular (which means it's not inversible), compute the pseudoinverse\n",
    "    inv_cov_matrix = np.linalg.pinv(cov_matrix)\n",
    "\n",
    "# Function to find the \"top_n\" most similar songs using Mahalanobis distance\n",
    "def find_top_similar_songs(songs_df, user_song, inv_cov_matrix, top_n=top_n):\n",
    "    user_song = np.array(user_song.values.flatten())\n",
    "    \n",
    "\n",
    "    distances = {}\n",
    "    for idx, song_features in songs_df.iterrows():\n",
    "        song_features = np.array(song_features.values.flatten())\n",
    "        # Calculate Mahalanobis distance between user song and current song\n",
    "        distances[idx] = distance.mahalanobis(user_song, song_features, inv_cov_matrix)\n",
    "    \n",
    "    # Top N most similar songs by distance\n",
    "    sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "    top_similar_indices = [idx for idx, _ in sorted_distances[:top_n]]\n",
    "    \n",
    "    top_songs = songs_df.loc[top_similar_indices]\n",
    "    top_distances = [distances[idx] for idx in top_similar_indices]\n",
    "    \n",
    "    return top_songs, top_distances\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "top_songs, top_distances = find_top_similar_songs(like_songs, num_user_input, inv_cov_matrix, top_n=top_n)\n",
    "recommended_tracks = songs[(songs.index.isin(top_songs.index))][['track_name','track_artist','track_album_name']]\n",
    "\n",
    "print(recommended_tracks)\n",
    "\n",
    "recommended_tracks = HTML(recommended_tracks.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_data =  songs[['danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "       'valence', 'tempo','track_artist_label','release_year']]\n",
    "\n",
    "mood_musics = mood_musics[['track_id', 'track_name', 'track_artist', 'track_popularity', \n",
    "                                           'playlist_genre', 'playlist_subgenre', 'year', 'mood']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class MusicRecommender:\n",
    "    def __init__(self, songs_df):\n",
    "        self.songs = self.preprocess_songs(songs_df)\n",
    "        self.kmeans = None\n",
    "        self.inv_cov_matrix = None\n",
    "        self.clustering_data = self.prepare_clustering_data()\n",
    "        self.train_kmeans()\n",
    "\n",
    "    def preprocess_songs(self, df):\n",
    "        \n",
    "        df.drop(columns=['playlist_name', 'playlist_id'], inplace=True)\n",
    "        df.drop_duplicates(subset=['track_name', 'track_artist'], inplace=True)\n",
    "        df = df[df['duration_ms'] > df['duration_ms'].quantile(0.01)]\n",
    "        df.dropna(inplace=True)\n",
    "        df['release_year'] = pd.to_datetime(df['track_album_release_date'], errors='coerce').dt.year\n",
    "        encoder = LabelEncoder()\n",
    "        df['track_artist_label'] = encoder.fit_transform(df['track_artist'])\n",
    "        df['track_album_id_label'] = encoder.fit_transform(df['track_album_id'])\n",
    "        df['artist_track'] = df.apply(lambda x: f\"{x['track_artist']} - {x['track_name']}\", axis=1)\n",
    "        return df\n",
    "\n",
    "    def prepare_clustering_data(self):\n",
    "        features = [\n",
    "            'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "            'speechiness', 'acousticness', 'instrumentalness',\n",
    "            'liveness', 'valence', 'tempo', 'track_artist_label', 'release_year'\n",
    "        ]\n",
    "        return self.songs[features]\n",
    "\n",
    "    def train_kmeans(self, n_clusters=8):\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters)\n",
    "        self.songs['kmeans_labels'] = self.kmeans.fit_predict(self.clustering_data)\n",
    "        self.clustering_data['kmeans_labels'] = self.kmeans.labels_\n",
    "        self.calculate_cov_matrix()\n",
    "\n",
    "    def calculate_cov_matrix(self):\n",
    "        like_songs = self.clustering_data[self.clustering_data['kmeans_labels'] == self.clustering_data['kmeans_labels'][0]]\n",
    "        cov_matrix = np.cov(like_songs, rowvar=False)\n",
    "        try:\n",
    "            self.inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "        except np.linalg.LinAlgError:\n",
    "            self.inv_cov_matrix = np.linalg.pinv(cov_matrix)\n",
    "\n",
    "    def recommend_by_song_name(self, song_name, top_n=10):\n",
    "        user_input = self.songs[self.songs['artist_track'] == song_name]\n",
    "        num_user_input = self.clustering_data.loc[user_input.index]\n",
    "        like_songs = self.clustering_data[self.clustering_data['kmeans_labels'] == num_user_input['kmeans_labels'].values[0]]\n",
    "        like_songs = like_songs.drop(index=user_input.index)\n",
    "        return self.find_top_similar_songs(like_songs, num_user_input, top_n)\n",
    "\n",
    "    def recommend_by_mood(self, mood, n=20):\n",
    "        mood_musics = self.songs[self.songs['mood'] == mood].sort_values(by='track_popularity', ascending=False).head(300)\n",
    "        mood_musics = mood_musics[['track_id', 'track_name', 'track_artist', 'track_popularity', 'playlist_genre', 'playlist_subgenre', 'year', 'mood']]\n",
    "        unique_years = mood_musics['year'].nunique()\n",
    "        songs_per_year = max(1, n // unique_years)\n",
    "        sampled_musics = mood_musics.groupby('year').apply(lambda x: x.sample(min(len(x), songs_per_year))).reset_index(drop=True)\n",
    "        if len(sampled_musics) < n:\n",
    "            additional_songs = mood_musics.drop(sampled_musics.index).sample(n - len(sampled_musics))\n",
    "            sampled_musics = pd.concat([sampled_musics, additional_songs]).reset_index(drop=True)\n",
    "        return sampled_musics.sample(n).reset_index(drop=True)\n",
    "\n",
    "    def recommend_by_characteristics(self, energy, danceability, speechiness, acousticness, top_n=10):\n",
    "        inference_df = pd.DataFrame({\n",
    "            'energy': [float(energy)], 'danceability': [float(danceability)],\n",
    "            'speechiness': [float(speechiness)], 'acousticness': [float(acousticness)]\n",
    "        })\n",
    "        # You would call a clustering model here and make label predictions on inference_df\n",
    "        # For now, this is a placeholder\n",
    "        return \"Step 1: Call Cluster model and make label predictions on inference_df\"\n",
    "\n",
    "    def find_top_similar_songs(self, songs_df, user_song, top_n=10):\n",
    "        user_song = np.array(user_song.values.flatten())\n",
    "        distances = {\n",
    "            idx: distance.mahalanobis(user_song, np.array(song_features.values.flatten()), self.inv_cov_matrix)\n",
    "            for idx, song_features in songs_df.iterrows()\n",
    "        }\n",
    "        sorted_distances = sorted(distances.items(), key=lambda x: x[1])\n",
    "        top_similar_indices = [idx for idx, _ in sorted_distances[:top_n]]\n",
    "        return self.songs.loc[top_similar_indices, ['track_name', 'track_artist', 'track_album_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JjYmvA8qTPOh_dVAVkvsapP-xtes7F4h\n",
      "To: /Users/gabrielvictorgomesferreira/artificial_intelligence/isu_classes/projects/Spotify-Data-Project/code/final/spotify_songs.csv\n",
      "100%|██████████| 7.97M/7.97M [00:00<00:00, 8.46MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>playlist_genre</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6f807x0ima9a1j3VPbc7VN</td>\n",
       "      <td>I Don't Care (with Justin Bieber) - Loud Luxur...</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>66</td>\n",
       "      <td>2oCs0DGTsRO98Gh5ZSl2Cx</td>\n",
       "      <td>I Don't Care (with Justin Bieber) [Loud Luxury...</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-2.634</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>122.036</td>\n",
       "      <td>194754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0r7CVbZTWZgbTCYdfa2P31</td>\n",
       "      <td>Memories - Dillon Francis Remix</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>67</td>\n",
       "      <td>63rPSO264uRjW1X5E6cWv6</td>\n",
       "      <td>Memories (Dillon Francis Remix)</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>99.972</td>\n",
       "      <td>162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1z1Hg7Vb0AhHDiEmnDE79l</td>\n",
       "      <td>All the Time - Don Diablo Remix</td>\n",
       "      <td>Zara Larsson</td>\n",
       "      <td>70</td>\n",
       "      <td>1HoSmj2eLcsrR0vE9gThr4</td>\n",
       "      <td>All the Time (Don Diablo Remix)</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>124.008</td>\n",
       "      <td>176616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75FpbthrwQmzHlBJLuGdC7</td>\n",
       "      <td>Call You Mine - Keanu Silva Remix</td>\n",
       "      <td>The Chainsmokers</td>\n",
       "      <td>60</td>\n",
       "      <td>1nqYsOef1yKKuGOVchbsk6</td>\n",
       "      <td>Call You Mine - The Remixes</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>121.956</td>\n",
       "      <td>169093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1e8PAfcKUYoKkxPhrHqw4x</td>\n",
       "      <td>Someone You Loved - Future Humans Remix</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>69</td>\n",
       "      <td>7m7vv9wlQ4i0LFuJiE2zsQ</td>\n",
       "      <td>Someone You Loved (Future Humans Remix)</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>Pop Remix</td>\n",
       "      <td>37i9dQZF1DXcZDD7cfEKhW</td>\n",
       "      <td>pop</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>123.976</td>\n",
       "      <td>189052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32828</th>\n",
       "      <td>7bxnKAamR3snQ1VGLuVfC1</td>\n",
       "      <td>City Of Lights - Official Radio Edit</td>\n",
       "      <td>Lush &amp; Simon</td>\n",
       "      <td>42</td>\n",
       "      <td>2azRoBBWEEEYhqV6sb7JrT</td>\n",
       "      <td>City Of Lights (Vocal Mix)</td>\n",
       "      <td>2014-04-28</td>\n",
       "      <td>♥ EDM LOVE 2020</td>\n",
       "      <td>6jI1gFr6ANFtT8MmTvA2Ux</td>\n",
       "      <td>edm</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.814</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>128.170</td>\n",
       "      <td>204375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32829</th>\n",
       "      <td>5Aevni09Em4575077nkWHz</td>\n",
       "      <td>Closer - Sultan &amp; Ned Shepard Remix</td>\n",
       "      <td>Tegan and Sara</td>\n",
       "      <td>20</td>\n",
       "      <td>6kD6KLxj7s8eCE3ABvAyf5</td>\n",
       "      <td>Closer Remixed</td>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>♥ EDM LOVE 2020</td>\n",
       "      <td>6jI1gFr6ANFtT8MmTvA2Ux</td>\n",
       "      <td>edm</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.462</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>128.041</td>\n",
       "      <td>353120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32830</th>\n",
       "      <td>7ImMqPP3Q1yfUHvsdn7wEo</td>\n",
       "      <td>Sweet Surrender - Radio Edit</td>\n",
       "      <td>Starkillers</td>\n",
       "      <td>14</td>\n",
       "      <td>0ltWNSY9JgxoIZO4VzuCa6</td>\n",
       "      <td>Sweet Surrender (Radio Edit)</td>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>♥ EDM LOVE 2020</td>\n",
       "      <td>6jI1gFr6ANFtT8MmTvA2Ux</td>\n",
       "      <td>edm</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.899</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>127.989</td>\n",
       "      <td>210112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32831</th>\n",
       "      <td>2m69mhnfQ1Oq6lGtXuYhgX</td>\n",
       "      <td>Only For You - Maor Levi Remix</td>\n",
       "      <td>Mat Zo</td>\n",
       "      <td>15</td>\n",
       "      <td>1fGrOkHnHJcStl14zNx8Jy</td>\n",
       "      <td>Only For You (Remixes)</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>♥ EDM LOVE 2020</td>\n",
       "      <td>6jI1gFr6ANFtT8MmTvA2Ux</td>\n",
       "      <td>edm</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.361</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>128.008</td>\n",
       "      <td>367432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32832</th>\n",
       "      <td>29zWqhca3zt5NsckZqDf6c</td>\n",
       "      <td>Typhoon - Original Mix</td>\n",
       "      <td>Julian Calor</td>\n",
       "      <td>27</td>\n",
       "      <td>0X3mUOm6MhxR7PzxG95rAo</td>\n",
       "      <td>Typhoon/Storm</td>\n",
       "      <td>2014-03-03</td>\n",
       "      <td>♥ EDM LOVE 2020</td>\n",
       "      <td>6jI1gFr6ANFtT8MmTvA2Ux</td>\n",
       "      <td>edm</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.571</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>127.984</td>\n",
       "      <td>337500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32833 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id  \\\n",
       "0      6f807x0ima9a1j3VPbc7VN   \n",
       "1      0r7CVbZTWZgbTCYdfa2P31   \n",
       "2      1z1Hg7Vb0AhHDiEmnDE79l   \n",
       "3      75FpbthrwQmzHlBJLuGdC7   \n",
       "4      1e8PAfcKUYoKkxPhrHqw4x   \n",
       "...                       ...   \n",
       "32828  7bxnKAamR3snQ1VGLuVfC1   \n",
       "32829  5Aevni09Em4575077nkWHz   \n",
       "32830  7ImMqPP3Q1yfUHvsdn7wEo   \n",
       "32831  2m69mhnfQ1Oq6lGtXuYhgX   \n",
       "32832  29zWqhca3zt5NsckZqDf6c   \n",
       "\n",
       "                                              track_name      track_artist  \\\n",
       "0      I Don't Care (with Justin Bieber) - Loud Luxur...        Ed Sheeran   \n",
       "1                        Memories - Dillon Francis Remix          Maroon 5   \n",
       "2                        All the Time - Don Diablo Remix      Zara Larsson   \n",
       "3                      Call You Mine - Keanu Silva Remix  The Chainsmokers   \n",
       "4                Someone You Loved - Future Humans Remix     Lewis Capaldi   \n",
       "...                                                  ...               ...   \n",
       "32828               City Of Lights - Official Radio Edit      Lush & Simon   \n",
       "32829                Closer - Sultan & Ned Shepard Remix    Tegan and Sara   \n",
       "32830                       Sweet Surrender - Radio Edit       Starkillers   \n",
       "32831                     Only For You - Maor Levi Remix            Mat Zo   \n",
       "32832                             Typhoon - Original Mix      Julian Calor   \n",
       "\n",
       "       track_popularity          track_album_id  \\\n",
       "0                    66  2oCs0DGTsRO98Gh5ZSl2Cx   \n",
       "1                    67  63rPSO264uRjW1X5E6cWv6   \n",
       "2                    70  1HoSmj2eLcsrR0vE9gThr4   \n",
       "3                    60  1nqYsOef1yKKuGOVchbsk6   \n",
       "4                    69  7m7vv9wlQ4i0LFuJiE2zsQ   \n",
       "...                 ...                     ...   \n",
       "32828                42  2azRoBBWEEEYhqV6sb7JrT   \n",
       "32829                20  6kD6KLxj7s8eCE3ABvAyf5   \n",
       "32830                14  0ltWNSY9JgxoIZO4VzuCa6   \n",
       "32831                15  1fGrOkHnHJcStl14zNx8Jy   \n",
       "32832                27  0X3mUOm6MhxR7PzxG95rAo   \n",
       "\n",
       "                                        track_album_name  \\\n",
       "0      I Don't Care (with Justin Bieber) [Loud Luxury...   \n",
       "1                        Memories (Dillon Francis Remix)   \n",
       "2                        All the Time (Don Diablo Remix)   \n",
       "3                            Call You Mine - The Remixes   \n",
       "4                Someone You Loved (Future Humans Remix)   \n",
       "...                                                  ...   \n",
       "32828                         City Of Lights (Vocal Mix)   \n",
       "32829                                     Closer Remixed   \n",
       "32830                       Sweet Surrender (Radio Edit)   \n",
       "32831                             Only For You (Remixes)   \n",
       "32832                                      Typhoon/Storm   \n",
       "\n",
       "      track_album_release_date    playlist_name             playlist_id  \\\n",
       "0                   2019-06-14        Pop Remix  37i9dQZF1DXcZDD7cfEKhW   \n",
       "1                   2019-12-13        Pop Remix  37i9dQZF1DXcZDD7cfEKhW   \n",
       "2                   2019-07-05        Pop Remix  37i9dQZF1DXcZDD7cfEKhW   \n",
       "3                   2019-07-19        Pop Remix  37i9dQZF1DXcZDD7cfEKhW   \n",
       "4                   2019-03-05        Pop Remix  37i9dQZF1DXcZDD7cfEKhW   \n",
       "...                        ...              ...                     ...   \n",
       "32828               2014-04-28  ♥ EDM LOVE 2020  6jI1gFr6ANFtT8MmTvA2Ux   \n",
       "32829               2013-03-08  ♥ EDM LOVE 2020  6jI1gFr6ANFtT8MmTvA2Ux   \n",
       "32830               2014-04-21  ♥ EDM LOVE 2020  6jI1gFr6ANFtT8MmTvA2Ux   \n",
       "32831               2014-01-01  ♥ EDM LOVE 2020  6jI1gFr6ANFtT8MmTvA2Ux   \n",
       "32832               2014-03-03  ♥ EDM LOVE 2020  6jI1gFr6ANFtT8MmTvA2Ux   \n",
       "\n",
       "      playlist_genre  ... key  loudness  mode  speechiness  acousticness  \\\n",
       "0                pop  ...   6    -2.634     1       0.0583      0.102000   \n",
       "1                pop  ...  11    -4.969     1       0.0373      0.072400   \n",
       "2                pop  ...   1    -3.432     0       0.0742      0.079400   \n",
       "3                pop  ...   7    -3.778     1       0.1020      0.028700   \n",
       "4                pop  ...   1    -4.672     1       0.0359      0.080300   \n",
       "...              ...  ...  ..       ...   ...          ...           ...   \n",
       "32828            edm  ...   2    -1.814     1       0.0936      0.076600   \n",
       "32829            edm  ...   0    -4.462     1       0.0420      0.001710   \n",
       "32830            edm  ...   6    -4.899     0       0.0481      0.108000   \n",
       "32831            edm  ...   2    -3.361     1       0.1090      0.007920   \n",
       "32832            edm  ...   5    -4.571     0       0.0385      0.000133   \n",
       "\n",
       "       instrumentalness  liveness  valence    tempo  duration_ms  \n",
       "0              0.000000    0.0653   0.5180  122.036       194754  \n",
       "1              0.004210    0.3570   0.6930   99.972       162600  \n",
       "2              0.000023    0.1100   0.6130  124.008       176616  \n",
       "3              0.000009    0.2040   0.2770  121.956       169093  \n",
       "4              0.000000    0.0833   0.7250  123.976       189052  \n",
       "...                 ...       ...      ...      ...          ...  \n",
       "32828          0.000000    0.0668   0.2100  128.170       204375  \n",
       "32829          0.004270    0.3750   0.4000  128.041       353120  \n",
       "32830          0.000001    0.1500   0.4360  127.989       210112  \n",
       "32831          0.127000    0.3430   0.3080  128.008       367432  \n",
       "32832          0.341000    0.7420   0.0894  127.984       337500  \n",
       "\n",
       "[32833 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess the data\n",
    "file_id = '1JjYmvA8qTPOh_dVAVkvsapP-xtes7F4h'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "output = 'spotify_songs.csv'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "songs = pd.read_csv('spotify_songs.csv')\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wp/7bp3qrzx7dx95tf0806th2rw0000gn/T/ipykernel_2640/456260882.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(inplace=True)\n",
      "/var/folders/wp/7bp3qrzx7dx95tf0806th2rw0000gn/T/ipykernel_2640/456260882.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['release_year'] = pd.to_datetime(df['track_album_release_date'], errors='coerce').dt.year\n",
      "/var/folders/wp/7bp3qrzx7dx95tf0806th2rw0000gn/T/ipykernel_2640/456260882.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['track_artist_label'] = encoder.fit_transform(df['track_artist'])\n",
      "/var/folders/wp/7bp3qrzx7dx95tf0806th2rw0000gn/T/ipykernel_2640/456260882.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['track_album_id_label'] = encoder.fit_transform(df['track_album_id'])\n",
      "/var/folders/wp/7bp3qrzx7dx95tf0806th2rw0000gn/T/ipykernel_2640/456260882.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['artist_track'] = df.apply(lambda x: f\"{x['track_artist']} - {x['track_name']}\", axis=1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m recommender \u001b[38;5;241m=\u001b[39m \u001b[43mMusicRecommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43msongs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommender\u001b[38;5;241m.\u001b[39mrecommend_by_mood(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHappy\u001b[39m\u001b[38;5;124m\"\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mMusicRecommender.__init__\u001b[0;34m(self, songs_df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minv_cov_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclustering_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_clustering_data()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_kmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m, in \u001b[0;36mMusicRecommender.train_kmeans\u001b[0;34m(self, n_clusters)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_kmeans\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mn_clusters)\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msongs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans_labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclustering_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans_labels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans\u001b[38;5;241m.\u001b[39mlabels_\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_cov_matrix()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1068\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1068\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlabels_\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1471\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \n\u001b[1;32m   1447\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1471\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1482\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/data_science/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "recommender = MusicRecommender(songs)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "print(recommender.recommend_by_mood(\"Happy\", n=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recommender.recommend_by_song_name(\"Artist - Track\", top_n=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
